import argparse
import ast
import datetime
import logging
import sys

import pandas
import pandas as pd

import config
from backtest.backtester import Backtester
from common import optimizer
from common.loader import get_class_from_name, pascal_to_snake
from data_providers.manager import DataManager
from recorders.db_recorder import DBRecorder
from recorders.http_recorder import HttpRecorder
from recorders.manager import RecorderManager


def run_backtest(selection_filename, strategy_filename, symbols, cash, commission, slippage, data_source, start_date, end_date,
                 risk_filename, risk_params, params, timeframe, compression, recorder=None, enable_plot=True):
    """æ‰§è¡Œå›žæµ‹"""
    # --- 1. è‡ªåŠ¨å‘çŽ°å¹¶åŠ è½½æ‰€æœ‰æ•°æ®æä¾›è€… ---
    data_manager = DataManager()

    # --- 2. æ‰§è¡Œé€‰è‚¡ ---
    if selection_filename:
        print("--- Running Selection Phase ---")
        selector_class = get_class_from_name(selection_filename, ['stock_selectors'])
        selector_instance = selector_class(data_manager=data_manager)
        selection_result = selector_instance.run_selection()
        if isinstance(selection_result, list):
            symbols = selection_result
        if isinstance(selection_result, pandas.DataFrame):
            symbols = selection_result.index.tolist()

        if not symbols:
            print("\nFatal: The selector did not return any symbols. Aborting.")
            return
        print(f"  Selector '{selection_filename}' selected {len(symbols)} symbols: {', '.join(symbols)}")
    elif not symbols:
        print("\nFatal: You must provide either --selection or --symbols. Aborting.")
        return

    print("--- Starting Backtest ---")
    print(f"  Selection: {selection_filename}")
    print(f"  Strategy: {strategy_filename}")
    print(f"  Risk Control: {risk_filename or 'None'}")
    print(f"  Symbols: {symbols}")
    print(f"  Backtest Period: {start_date} to {end_date}")
    print(f"  Initial Cash: {cash:,.2f}")
    print(f"  Commission: {commission:.4f}")

    # --- 3. èŽ·å–æ•°æ® ---
    print("\n--- Fetching Data ---")
    print(f"  Requesting data from: {start_date or 'origin'} to {end_date or 'latest'}")

    datas = {}
    for symbol in symbols:
        print(f"  Fetching data for: {symbol}")
        df = data_manager.get_data(
            symbol,
            start_date=start_date,
            end_date=end_date,
            specified_sources=data_source,
            timeframe=timeframe,
            compression=compression,
            refresh=args.refresh
        )
        if df is not None and not df.empty:
            datas[symbol] = df
        else:
            print(f"  Warning: Failed to fetch data for {symbol}. It will be excluded from the backtest.")

    if not datas:
        print("\nFatal: Could not fetch data for any of the specified symbols. Aborting.")
        return

    # --- 4. åˆå§‹åŒ–å›žæµ‹å™¨å¹¶è¿è¡Œ ---
    print("\n--- Initializing Backtester ---")
    strategy_class = get_class_from_name(strategy_filename, ['strategies'])

    risk_control_classes = []
    if risk_filename:
        # æ”¯æŒé€—å·åˆ†éš”çš„å¤šä¸ªé£ŽæŽ§ç­–ç•¥
        risk_names = risk_filename.split(',')
        for r_name in risk_names:
            r_name = r_name.strip()
            if r_name:
                cls = get_class_from_name(r_name, ['risk_controls', 'strategies'])
                risk_control_classes.append(cls)
        print(f"  Risk Control Modules: {risk_names}")
        print(f"  Risk Control Params: {risk_params}")

    backtester = Backtester(
        datas,
        strategy_class,
        params=params,
        start_date=start_date,
        end_date=end_date,
        cash=cash,
        commission=commission,
        slippage=slippage,
        risk_control_classes=risk_control_classes,
        risk_control_params=risk_params,
        timeframe=timeframe,
        compression=compression,
        recorder=recorder,
        enable_plot=enable_plot,
    )
    backtester.run()

    return backtester


if __name__ == '__main__':
    # 1. åˆ›å»ºå‘½ä»¤è¡Œè§£æžå™¨
    parser = argparse.ArgumentParser(
        description="é‡åŒ–å›žæµ‹æ¡†æž¶",
        formatter_class=argparse.RawTextHelpFormatter
    )

    # 2. æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument('strategy', type=str,
                        help="è¦è¿è¡Œçš„ç­–ç•¥æ–‡ä»¶å (ä¾‹å¦‚: sample_macd_cross_strategy.py æˆ– sample_macd_cross_strategy æˆ– my_pkg.my_strategy.MyStrategyClass)")
    parser.add_argument('--params', type=str, default='{}',
                        help="ç­–ç•¥å‚æ•° (JSONå­—ç¬¦ä¸², ä¾‹å¦‚: \"{\'selectTopK\': 2, \'target_buffer\': 0.95}\")")
    parser.add_argument('--selection', type=str, default=None, help="é€‰è‚¡å™¨æ–‡ä»¶å (ä½äºŽselectorsç›®å½• æˆ– è‡ªå®šä¹‰åŒ…è·¯å¾„)")
    parser.add_argument('--data_source', type=str, default=None,
                        help="æŒ‡å®šæ•°æ®æº (ä¾‹å¦‚: csv yf akshare tushare sxsc_tushare gm)")
    parser.add_argument('--symbols', type=str, default='SHSE.510300', help="ä»¥,åˆ†å‰²çš„å›žæµ‹æ ‡çš„ä»£ç  (é»˜è®¤: SHSE.510300)")
    parser.add_argument('--cash', type=float, default=None, help="åˆå§‹èµ„é‡‘ (å›žæµ‹é»˜è®¤: 100000.0ã€å®žç›˜é»˜è®¤å…¨ä»“)")
    parser.add_argument('--commission', type=float, default=0, help="æ‰‹ç»­è´¹çŽ‡ï¼Œä¾‹å¦‚ï¼šä¸‡1.5ä¸º:0.00015 (é»˜è®¤ï¼š0)")
    parser.add_argument('--slippage', type=float, default=0.001, help="æ»‘ç‚¹ï¼Œæ¨¡æ‹ŸçœŸå®žå¸‚åœºçš„å†²å‡»æˆæœ¬ (é»˜è®¤: 0.001)")
    parser.add_argument('--start_date', type=str, default=None, help="å›žæµ‹èµ·å§‹æ—¥æœŸ (ä¾‹å¦‚: 20241111)")
    parser.add_argument('--end_date', type=str, default=None, help="å›žæµ‹ç»“æŸæ—¥æœŸ (ä¾‹å¦‚: 20250101)")
    parser.add_argument('--risk', type=str, default=None, help="é£ŽæŽ§æ¨¡å—åç§° (ä½äºŽ risk_controlsç›®å½• æˆ– è‡ªå®šä¹‰åŒ…è·¯å¾„)")
    parser.add_argument('--risk_params', type=str, default='{}',
                        help="é£ŽæŽ§å‚æ•° (JSONå­—ç¬¦ä¸², ä¾‹å¦‚: \"{\'stop_loss\': 0.05}\")")
    bt_timeframes = ['Days', 'Weeks', 'Months', 'Minutes', 'Seconds']
    parser.add_argument('--timeframe', type=str, default='Days', choices=bt_timeframes,
                        help=f"Kçº¿æ—¶é—´ç»´åº¦ (é»˜è®¤: Days). æ”¯æŒ: {', '.join(bt_timeframes)}")
    parser.add_argument('--compression', type=int, default=1,
                        help="Kçº¿æ—¶é—´å‘¨æœŸ (é»˜è®¤: 1). ç»“åˆ timeframe, ä¾‹å¦‚ 30 Minutes")
    parser.add_argument('--desc', type=str, default=None,
                        help="æœ¬æ¬¡å›žæµ‹çš„æè¿°ä¿¡æ¯ (é»˜è®¤ä¸ºä¸å¸¦ .py çš„ç­–ç•¥æ–‡ä»¶å)")

    parser.add_argument('--no_plot', action='store_true', help="åœ¨æœåŠ¡å™¨çŽ¯å¢ƒä¸‹ç¦ç”¨ç»˜å›¾")
    parser.add_argument('--refresh', action='store_true', help="å¼ºåˆ¶åˆ·æ–°CACHE_DATAæ•°æ®")
    parser.add_argument('--config', type=str, default='{}',
                        help="è¦†ç›–config.pyé…ç½® (JSONå­—ç¬¦ä¸², ä¾‹å¦‚: \"{'GM_TOKEN':'xxx','LOG':False}\")")
    # Optimizer ä¸“ç”¨å‚æ•°
    parser.add_argument('--opt_params', type=str, default=None, help="[ä¼˜åŒ–æ¨¡å¼] ä¼˜åŒ–å‚æ•°ç©ºé—´å®šä¹‰ JSON")
    parser.add_argument('--n_trials', type=int, default=None, help="[ä¼˜åŒ–æ¨¡å¼] å°è¯•æ¬¡æ•° (é»˜è®¤: è‡ªåŠ¨æŽ¨æ–­)")
    parser.add_argument('--n_jobs', type=int, default=-1, help="[ä¼˜åŒ–æ¨¡å¼] å¹¶è¡Œæ ¸å¿ƒæ•° (-1 è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰æ ¸å¿ƒ)")
    parser.add_argument('--metric', type=str, default='mix_score_origin',
                        help="[ä¼˜åŒ–æ¨¡å¼] ä¼˜åŒ–ç›®æ ‡ (æ”¯æŒé€—å·åˆ†éš”çš„å¤šç§æœ‰æŒ‡æ ‡ä¸²è¡Œæ‰§è¡Œ)")
    parser.add_argument('--study_name', type=str, default=None, help="[ä¼˜åŒ–æ¨¡å¼] è®­ç»ƒåç§°")
    parser.add_argument('--train_roll_period', type=str, default=None,
                        help="[ä¼˜åŒ–æ¨¡å¼] è®­ç»ƒé›†æ»šåŠ¨å‘¨æœŸ (ä»Žæµ‹è¯•é›†å¼€å§‹æ—¶é—´å¾€å‰æŽ¨)ã€‚ä¾‹å¦‚ï¼š1y, 3y")
    parser.add_argument('--test_roll_period', type=str, default=None,
                        help="[ä¼˜åŒ–æ¨¡å¼] æµ‹è¯•é›†æ»šåŠ¨å‘¨æœŸ (ä»Žå½“å‰æ—¶é—´/end_dateå¾€å‰æŽ¨)ã€‚ä¾‹å¦‚ï¼š1y, 3m, 6mã€‚é»˜è®¤ä¸ºæ— ç‹¬ç«‹æµ‹è¯•é›†")
    parser.add_argument('--train_ratio', type=float, default=None, help="[ä¼˜åŒ–æ¨¡å¼] æ¯”ä¾‹åˆ‡åˆ†è®­ç»ƒé›†ã€æµ‹è¯•é›†ï¼Œä¾‹å¦‚0.5")
    parser.add_argument('--train_period', type=str, default=None, help="[ä¼˜åŒ–æ¨¡å¼] è®­ç»ƒé›†æ—¶æ®µ")
    parser.add_argument('--test_period', type=str, default=None, help="[ä¼˜åŒ–æ¨¡å¼] æµ‹è¯•é›†æ—¶æ®µ")

    # å®žç›˜å‚æ•°
    parser.add_argument('--connect', type=str, default=None,
                        help="å®žç›˜è¿žæŽ¥é…ç½®ï¼Œæ ¼å¼ 'broker:env' (ä¾‹å¦‚: 'gm_broker:sim')")

    # 3. è§£æžå‚æ•°
    args = parser.parse_args()

    # ==========================================
    # å…¨å±€æ—¶é—´è‡ªåŠ¨æŽ¨æ–­é€»è¾‘ (Auto-Inference)
    # ä½œç”¨ï¼šæ”¯æŒç¼ºçœ start_date/end_date çš„è‡ªåŠ¨åŒ–å›žæµ‹
    # ==========================================
    # 1. è‡ªåŠ¨è¡¥å…¨ end_date (é»˜è®¤ä¸ºå½“å‰ç³»ç»Ÿæ—¶é—´)
    if not args.end_date:
        args.end_date = datetime.datetime.now().strftime('%Y%m%d')

    # 2. è‡ªåŠ¨è¡¥å…¨ start_date
    # æ³¨æ„ï¼šå¦‚æžœæ˜¯å®žç›˜æ¨¡å¼(--connect)ï¼Œå¼•æ“Žæœ‰è‡ªå·±çš„ 1 å¹´é¢„çƒ­é€»è¾‘ï¼Œæ— éœ€åœ¨æ­¤å¼ºè¡Œå¹²é¢„
    if not args.start_date and not args.connect:
        # é»˜è®¤æœ€å¤§å…¬çº¦æ•°å›žæº¯å‘¨æœŸï¼š3å¹´
        # ä½¿ç”¨ pd.DateOffset å¯ä»¥å®Œç¾Žå¤„ç†é—°å¹´(Leap Year)çš„å¤©æ•°å·®å¼‚
        end_dt = pd.to_datetime(args.end_date)
        start_dt = end_dt - pandas.DateOffset(years=3)
        args.start_date = start_dt.strftime('%Y%m%d')
        print(f"\n[System] ðŸ’¡ start_date omitted. Auto-inferred to: {args.start_date} (3 years lookback).")

    # è¦†ç›–config.py
    if args.config:
        override_config = ast.literal_eval(args.config)
        print(f"\n--- Applying Config Overrides ---")
        for key, value in override_config.items():
            if hasattr(config, key):
                setattr(config, key, value)
                print(f"  [Config] Overriding {key} = {value}")

    # å°†é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨
    symbol_list = [s.strip() for s in args.symbols.split(',')]

    # åœ¨è¿™é‡Œè§£æž JSON å­—ç¬¦ä¸²ä¸ºå­—å…¸
    try:
        s_params = ast.literal_eval(args.params)
    except (ValueError, SyntaxError) as e:
        print(f"Error parsing params JSON: {e}")
        s_params = {}

    try:
        r_params = ast.literal_eval(args.risk_params)
    except (ValueError, SyntaxError) as e:
        print(f"Error parsing risk_params JSON: {e}")
        r_params = {}

    # ==========================
    # å®žç›˜æ¨¡å¼
    # ==========================
    if args.connect:
        if ':' not in args.connect:
            print("Error: --connect format must be 'broker:env' (e.g. gm_broker:sim)")
            sys.exit(1)

        broker_name, conn_name = args.connect.split(':', 1)

        # æ”¶é›†æ‰§è¡Œå‚æ•° (Execution Args)
        # è¿™äº›å‚æ•°ä¹‹å‰åªç”¨äºŽå†…éƒ¨å›žæµ‹ï¼ŒçŽ°åœ¨æˆ‘ä»¬ä¹Ÿä¼ ç»™ Broker
        exec_args = {
            'start_date': args.start_date,
            'end_date': args.end_date,
            'cash': args.cash,
            'commission': args.commission,
            'slippage': args.slippage,
            # é€ä¼ é€‰è‚¡å™¨å’Œæ ‡çš„å‚æ•°
            'selection': args.selection,
            # åŒæ—¶ä¹Ÿå¤„ç† symbols (è½¬ä¸ºåˆ—è¡¨)ï¼Œä»¥é˜²æ²¡æœ‰é€‰è‚¡å™¨æ—¶ä½¿ç”¨
            'symbols': [s.strip() for s in args.symbols.split(',')] if args.symbols else []
        }

        # å»¶è¿Ÿå¯¼å…¥ launcherï¼Œé¿å…å›žæµ‹æ—¶å¼•å…¥ä¸å¿…è¦çš„ä¾èµ–
        from live_trader.engine import launch_live

        launch_live(broker_name, conn_name, args.strategy, s_params, **exec_args)
        sys.exit(0)

    # ==========================
    # ä¼˜åŒ–æ¨¡å¼
    # ==========================
    if args.opt_params:
        import copy
        import time

        print(f"\n>>> Mode: PARAMETER OPTIMIZATION (Target: {args.metric}) <<<")

        # 1. è§£æžä¼ å…¥çš„ metric (æ”¯æŒå•ä¸ªæˆ–é€—å·åˆ†éš”çš„å¤šä¸ª)
        metrics_list = [m.strip() for m in args.metric.split(',')]

        # --- å˜æ›´ç‚¹ 2: æ˜¾å¼å…³é—­æ—¥å¿— (ä»Ž optimizer.py ç§»è‡³æ­¤å¤„) ---
        config.LOG = False
        logging.getLogger("optuna").setLevel(logging.INFO)

        try:
            opt_p_def = ast.literal_eval(args.opt_params)
        except Exception as e:
            print(f"Error parsing opt_params JSON: {e}")
            sys.exit(1)

        final_reports = []
        total_metrics = len(metrics_list)

        for idx, current_metric in enumerate(metrics_list, 1):
            print(f"\n\n{'=' * 65}")
            print(f"ðŸš€ [æŒ‡æ ‡ {idx}/{total_metrics} æ­£åœ¨è®­ç»ƒ]: {current_metric}")
            print(f"{'=' * 65}")

            # æ·±æ‹·è´ argsï¼Œç¡®ä¿ç‰©ç†éš”ç¦»
            current_args = copy.deepcopy(args)
            current_args.metric = current_metric

            start_time = time.time()

            try:
                job = optimizer.OptimizationJob(
                    args=current_args,
                    fixed_params=s_params,
                    opt_params_def=opt_p_def,
                    risk_params=r_params
                )

                # æ‰§è¡Œä¼˜åŒ–å¹¶æŽ¥æ”¶è¿”å›žçš„å­—å…¸æˆ˜æŠ¥
                result_dict = job.run()
                elapsed_hours = (time.time() - start_time) / 3600.0

                if result_dict and isinstance(result_dict, dict):
                    result_dict['metric_name'] = current_args.metric
                    result_dict['elapsed_hours'] = elapsed_hours
                    result_dict['study_db'] = current_args.study_name
                    final_reports.append(result_dict)

            except Exception as e:
                print(f"\n[è‡´å‘½é”™è¯¯] æŒ‡æ ‡ '{current_metric}' è®­ç»ƒå´©æºƒ: {e}")
                import traceback

                traceback.print_exc()
                print(">>> å¼•æ“Žé˜²å®•æœºä¿æŠ¤è§¦å‘ï¼Œå¼ºè¡Œåˆ‡å…¥ä¸‹ä¸€ä¸ªæŒ‡æ ‡...")
                continue

        if final_reports:
            print(">>> å¤šæŒ‡æ ‡è®­ç»ƒç»“æžœæ±‡æ€»(MULTI-METRIC BANDIT SUMMARY) <<<")

            header = f"| {'æŒ‡æ ‡ (Metric)':<18} | {'æœ€é«˜å¾—åˆ† (Score)':<15} | {'è€—æ—¶ (h)':<8} | {'å…³è”æ—¥å¿— (Log)'}"
            print("-" * 90)
            print(header)
            print("-" * 90)

            for r in final_reports:
                m_str = str(r.get('metric_name', 'Unknown'))[:18]
                s_str = str(r.get('best_score', 'N/A'))[:15]
                t_str = f"{r.get('elapsed_hours', 0):.1f}"
                db_str = str(r.get('log_file', 'N/A'))
                print(f"| {m_str:<18} | {s_str:<15} | {t_str:<8} | {db_str}")

            print("-" * 90 + "\n")

            print("è¯·åœ¨ Dashboard ä¸­å›žæ”¾å¹¶æŽ’æŸ¥å­¤ç‚¹: ")
            for r in final_reports:
                if r.get('log_file'):
                    print(f"optuna-dashboard {r.get('log_file')}")
        else:
            print("\n[è­¦å‘Š] æ‰€æœ‰æŒ‡æ ‡å‡æœªè¿”å›žç»“æžœ")

        sys.exit(0)

    # ==========================
    # å›žæµ‹æ¨¡å¼
    # ==========================
    recorder_manager = RecorderManager()
    if config.DB_ENABLED:
        try:
            recorder_manager.add_recorder(DBRecorder(
                strategy_name=args.strategy, description=args.desc, params=s_params,
                start_date=args.start_date, end_date=args.end_date,
                initial_cash=args.cash if args.cash is not None else 100000.0, commission=args.commission
            ))
        except Exception as e:
            print(f"Failed to init DBRecorder: {e}")

    if hasattr(config, 'HTTP_LOG_URL') and config.HTTP_LOG_URL:
        recorder_manager.add_recorder(HttpRecorder(endpoint_url=config.HTTP_LOG_URL))

    run_backtest(
        selection_filename=args.selection,
        strategy_filename=args.strategy,
        symbols=symbol_list,
        cash=args.cash if args.cash is not None else 100000.0,
        commission=args.commission,
        slippage=args.slippage,
        data_source=args.data_source,
        start_date=args.start_date,
        end_date=args.end_date,
        risk_filename=args.risk,
        risk_params=r_params,
        params=s_params,
        timeframe=args.timeframe,
        compression=args.compression,
        recorder=recorder_manager,
        enable_plot=not args.no_plot,
    )
    print("\n--- Backtest Finished ---")